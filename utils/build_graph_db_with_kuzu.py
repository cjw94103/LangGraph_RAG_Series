"""
HybridKuzuRAG: Graph(êµ¬ì¡°) + Vector(ë¬¸ë§¥) í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œìŠ¤í…œ
- RetrieverëŠ” Documents ê°ì²´ë§Œ ë°˜í™˜ (LLM ë‹µë³€ ìƒì„± ì—†ìŒ)
"""

from langchain_experimental.graph_transformers import LLMGraphTransformer
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.documents import Document
from langchain_kuzu import KuzuGraph, KuzuQAChain
from langchain_community.vectorstores import FAISS
from langchain_core.retrievers import BaseRetriever
from langchain_core.callbacks import CallbackManagerForRetrieverRun
import kuzu
from typing import List, Optional, Set, Tuple, Dict
from collections import defaultdict


class HybridKuzuRAG:
    """
    ê·¸ë˜í”„ êµ¬ì¡° + ë¬¸ë§¥ ê²€ìƒ‰ì„ ê²°í•©í•œ Hybrid RAG ì‹œìŠ¤í…œ
    
    íŠ¹ì§•:
    - ìë™ ë…¸ë“œ/ê´€ê³„ ì¶”ì¶œ (LLM ê¸°ë°˜)
    - ê·¸ë˜í”„ êµ¬ì¡° ê²€ìƒ‰ (ì—”í‹°í‹° ê´€ê³„)
    - ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ (ë¬¸ë§¥/ì˜ë¯¸)
    - Documents ê°ì²´ ì§ì ‘ ë°˜í™˜ (LLM ë‹µë³€ ìƒì„± ì—†ìŒ)
    """
    
    def __init__(
        self, 
        llm_model: str = "gpt-4o",
        embedding_model: str = "text-embedding-3-small",
        in_memory: bool = True,
        db_path: Optional[str] = None
    ):
        """
        ì´ˆê¸°í™”
        
        Args:
            llm_model: LLM ëª¨ë¸ ì´ë¦„ (ê·¸ë˜í”„ ì¶”ì¶œìš©)
            embedding_model: Embedding ëª¨ë¸ ì´ë¦„
            in_memory: Trueë©´ ë©”ëª¨ë¦¬ì—, Falseë©´ ë””ìŠ¤í¬ì— ì €ì¥
            db_path: ë””ìŠ¤í¬ ì €ì¥ ì‹œ ê²½ë¡œ (in_memory=Falseì¼ ë•Œ í•„ìˆ˜)
        """
        self.llm = ChatOpenAI(model=llm_model, temperature=0)
        self.embeddings = OpenAIEmbeddings(model=embedding_model)
        
        # Kuzu GraphDB ì´ˆê¸°í™”
        if in_memory or db_path is None:
            print("ğŸ§  In-Memory ëª¨ë“œë¡œ Kuzu ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±")
            self.db = kuzu.Database()
            self.db_path = ":memory:"
        else:
            print(f"ğŸ’¾ ë””ìŠ¤í¬ ê¸°ë°˜ ëª¨ë“œë¡œ Kuzu ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±: {db_path}")
            self.db = kuzu.Database(db_path)
            self.db_path = db_path
        
        self.conn = kuzu.Connection(self.db)
        
        # Vector Store
        self.vector_store = None
        self.original_documents = []
        
        # ìŠ¤í‚¤ë§ˆ ì •ë³´ ì €ì¥
        self.discovered_node_types: Set[str] = set()
        self.discovered_relationships: Set[Tuple[str, str, str]] = set()
        self.node_properties: defaultdict = defaultdict(set)
        self.rel_properties: defaultdict = defaultdict(set)
        
        # Graph Transformer ì´ˆê¸°í™” (ìŠ¤í‚¤ë§ˆ ì œì•½ ì—†ìŒ - ìë™ ì¶”ì¶œ)
        self.graph_transformer = LLMGraphTransformer(
            llm=self.llm,
            node_properties=True,
            relationship_properties=True
        )
        
        # Graph ë˜í¼
        self.graph = None
        self.graph_chain = None
    
    def build_from_documents(self, documents: List[Document]) -> List:
        """
        Document ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° Hybrid RAG ì‹œìŠ¤í…œ êµ¬ì¶•
        
        Args:
            documents: LangChain Document ê°ì²´ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            graph_documents: ì¶”ì¶œëœ ê·¸ë˜í”„ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        print("=" * 70)
        print("ğŸ”§ HYBRID RAG êµ¬ì¶• ì‹œì‘")
        print("=" * 70)
        print("  ì „ëµ: Graph (ì—”í‹°í‹°/ê´€ê³„ êµ¬ì¡°) + Vector (ë¬¸ë§¥/ì˜ë¯¸)")
        print()
        
        self.original_documents = documents
        
        # ========================================
        # STEP 1: ê·¸ë˜í”„ êµ¬ì¡° ì¶”ì¶œ (LLM ìë™)
        # ========================================
        print("ğŸ“Š [STEP 1/3] ê·¸ë˜í”„ êµ¬ì¡° ì¶”ì¶œ ì¤‘...")
        print("  - LLMì´ ë¬¸ì„œì—ì„œ ì—”í‹°í‹°ì™€ ê´€ê³„ë¥¼ ìë™ ì¶”ì¶œí•©ë‹ˆë‹¤")
        
        graph_documents = self.graph_transformer.convert_to_graph_documents(documents)
        
        total_nodes = sum(len(gd.nodes) for gd in graph_documents)
        total_rels = sum(len(gd.relationships) for gd in graph_documents)
        
        print(f"  âœ“ {total_nodes}ê°œ ë…¸ë“œ ì¶”ì¶œ ì™„ë£Œ")
        print(f"  âœ“ {total_rels}ê°œ ê´€ê³„ ì¶”ì¶œ ì™„ë£Œ")
        
        # ìŠ¤í‚¤ë§ˆ í•™ìŠµ
        print("\n  ğŸ“š ì¶”ì¶œëœ ì—”í‹°í‹° íƒ€ì…:")
        for graph_doc in graph_documents:
            for node in graph_doc.nodes:
                if node.type not in self.discovered_node_types:
                    print(f"    - {node.type}")
                self.discovered_node_types.add(node.type)
                
                for prop in node.properties.keys():
                    self.node_properties[node.type].add(prop)
            
            for rel in graph_doc.relationships:
                rel_tuple = (rel.source.type, rel.type, rel.target.type)
                self.discovered_relationships.add(rel_tuple)
                
                for prop in rel.properties.keys():
                    self.rel_properties[rel.type].add(prop)
        
        print(f"\n  âœ“ ì´ {len(self.discovered_node_types)}ê°œ ë…¸ë“œ íƒ€ì…")
        print(f"  âœ“ ì´ {len(self.discovered_relationships)}ê°œ ê´€ê³„ íƒ€ì…")
        
        # Kuzu ìŠ¤í‚¤ë§ˆ ìƒì„± ë° ë°ì´í„° ì‚½ì…
        print("\n  ğŸ—ï¸  Kuzu ìŠ¤í‚¤ë§ˆ ìƒì„± ì¤‘...")
        self._create_kuzu_schema()
        
        print("  ğŸ’¾ ê·¸ë˜í”„ ë°ì´í„° ì‚½ì… ì¤‘...")
        inserted_count = self._insert_graph_data(graph_documents)
        print(f"  âœ“ {inserted_count}ê°œ ë…¸ë“œ ì‚½ì… ì™„ë£Œ")
        
        # ========================================
        # STEP 2: ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶•
        # ========================================
        print("\nğŸ”¢ [STEP 2/3] ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶• ì¤‘...")
        print("  - ë¬¸ì„œ ì „ì²´ë¥¼ ì„ë² ë”©í•˜ì—¬ ì˜ë¯¸ ê²€ìƒ‰ì„ ì§€ì›í•©ë‹ˆë‹¤")
        
        self.vector_store = FAISS.from_documents(
            documents,
            self.embeddings
        )
        print(f"  âœ“ {len(documents)}ê°œ ë¬¸ì„œ ì„ë² ë”© ì™„ë£Œ")
        
        # ========================================
        # STEP 3: Graph ë˜í¼ ì´ˆê¸°í™”
        # ========================================
        self.graph = KuzuGraph(self.db, allow_dangerous_requests=True)
        self.graph_chain = KuzuQAChain.from_llm(
            llm=self.llm,
            graph=self.graph,
            verbose=False,
            allow_dangerous_requests=True
        )
        
        # ========================================
        # STEP 4: ì™„ë£Œ
        # ========================================
        print("\nâœ… [STEP 3/3] Hybrid RAG êµ¬ì¶• ì™„ë£Œ!")
        print("=" * 70)
        print("  ğŸ“Š ê·¸ë˜í”„: ì—”í‹°í‹° ê´€ê³„ êµ¬ì¡° (ëˆ„ê°€, ë¬´ì—‡ì„, ì–´ë–»ê²Œ)")
        print("  ğŸ”¢ ë²¡í„°: ë¬¸ë§¥ ì˜ë¯¸ ê²€ìƒ‰ (ìœ ì‚¬í•œ ë‚´ìš© ì°¾ê¸°)")
        print("=" * 70)
        
        return graph_documents
    
    def _create_kuzu_schema(self):
        """í•™ìŠµëœ ìŠ¤í‚¤ë§ˆë¡œ Kuzu í…Œì´ë¸” ë™ì  ìƒì„±"""
        
        # ë…¸ë“œ í…Œì´ë¸” ìƒì„±
        for node_type in self.discovered_node_types:
            properties = self.node_properties[node_type]
            
            # ê¸°ë³¸ êµ¬ì¡°: id + PRIMARY KEY
            prop_definitions = ["id STRING", "PRIMARY KEY(id)"]
            
            # ì¶”ê°€ ì†ì„±
            for prop in properties:
                if prop != 'id':
                    prop_definitions.append(f"{prop} STRING")
            
            create_query = f"""
                CREATE NODE TABLE IF NOT EXISTS {node_type} (
                    {', '.join(prop_definitions)}
                )
            """
            
            try:
                self.conn.execute(create_query)
            except Exception as e:
                print(f"    âš ï¸  {node_type} í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
        
        # ê´€ê³„ í…Œì´ë¸” ìƒì„±
        for source_type, rel_type, target_type in self.discovered_relationships:
            properties = self.rel_properties[rel_type]
            
            # ê´€ê³„ ì´ë¦„ ì •ê·œí™” (íŠ¹ìˆ˜ë¬¸ì ì œê±°)
            rel_name = f"{source_type}_{rel_type}_{target_type}".replace("-", "_").replace(" ", "_")
            
            prop_definitions = []
            for prop in properties:
                prop_definitions.append(f"{prop} STRING")
            
            if prop_definitions:
                create_query = f"""
                    CREATE REL TABLE IF NOT EXISTS {rel_name} (
                        FROM {source_type} TO {target_type},
                        {', '.join(prop_definitions)}
                    )
                """
            else:
                create_query = f"""
                    CREATE REL TABLE IF NOT EXISTS {rel_name} (
                        FROM {source_type} TO {target_type}
                    )
                """
            
            try:
                self.conn.execute(create_query)
            except Exception as e:
                print(f"    âš ï¸  {rel_name} ê´€ê³„ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _insert_graph_data(self, graph_documents) -> int:
        """
        ê·¸ë˜í”„ ë°ì´í„°ë¥¼ Kuzuì— ì‚½ì…
        
        Returns:
            inserted_count: ì‚½ì…ëœ ë…¸ë“œ ê°œìˆ˜
        """
        inserted_nodes = set()
        
        for graph_doc in graph_documents:
            # ë…¸ë“œ ì‚½ì…
            for node in graph_doc.nodes:
                node_key = (node.type, node.id)
                if node_key in inserted_nodes:
                    continue
                
                # ì†ì„± ì²˜ë¦¬ (íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„)
                props = {"id": node.id}
                for k, v in node.properties.items():
                    if k != 'id':
                        # SQL injection ë°©ì§€: ì‘ì€ë”°ì˜´í‘œ ì´ìŠ¤ì¼€ì´í”„
                        props[k] = str(v).replace("'", "''")
                
                # INSERT ì¿¼ë¦¬ ìƒì„±
                columns = ', '.join(props.keys())
                values = ', '.join([f"'{v}'" for v in props.values()])
                
                insert_query = f"""
                    CREATE (:{node.type} {{{columns}: [{values}]}})
                """
                
                try:
                    self.conn.execute(insert_query)
                    inserted_nodes.add(node_key)
                except Exception as e:
                    # ì¤‘ë³µ ë“±ì˜ ì—ëŸ¬ëŠ” ë¬´ì‹œ
                    pass
            
            # ê´€ê³„ ì‚½ì…
            for rel in graph_doc.relationships:
                rel_name = f"{rel.source.type}_{rel.type}_{rel.target.type}".replace("-", "_").replace(" ", "_")
                
                # ê´€ê³„ ì†ì„± ì²˜ë¦¬
                if rel.properties:
                    props_str = ', '.join([
                        f"{k}: '{str(v).replace(chr(39), chr(39)+chr(39))}'" 
                        for k, v in rel.properties.items()
                    ])
                    match_query = f"""
                        MATCH (a:{rel.source.type}), (b:{rel.target.type})
                        WHERE a.id = '{rel.source.id}' AND b.id = '{rel.target.id}'
                        CREATE (a)-[:{rel_name} {{{props_str}}}]->(b)
                    """
                else:
                    match_query = f"""
                        MATCH (a:{rel.source.type}), (b:{rel.target.type})
                        WHERE a.id = '{rel.source.id}' AND b.id = '{rel.target.id}'
                        CREATE (a)-[:{rel_name}]->(b)
                    """
                
                try:
                    self.conn.execute(match_query)
                except Exception as e:
                    # ì¤‘ë³µ ê´€ê³„ ë“±ì˜ ì—ëŸ¬ëŠ” ë¬´ì‹œ
                    pass
        
        return len(inserted_nodes)
    
    def create_retriever(
        self, 
        search_mode: str = "both",
        vector_k: int = 5
    ):
        """
        í•˜ì´ë¸Œë¦¬ë“œ Retriever ìƒì„± (Documents ê°ì²´ ë°˜í™˜)
        
        Args:
            search_mode: ê²€ìƒ‰ ëª¨ë“œ
                - "graph": ê·¸ë˜í”„ êµ¬ì¡°ë§Œ ì‚¬ìš© (ì—”í‹°í‹°/ê´€ê³„)
                - "vector": ë²¡í„° ê²€ìƒ‰ë§Œ ì‚¬ìš© (ë¬¸ë§¥/ì˜ë¯¸)
                - "both": í•˜ì´ë¸Œë¦¬ë“œ (ë‘˜ ë‹¤ ì‚¬ìš©) â­ ê¶Œì¥
            vector_k: ë²¡í„° ê²€ìƒ‰ ì‹œ ë°˜í™˜í•  ë¬¸ì„œ ê°œìˆ˜
            
        Returns:
            HybridRetriever: Documentsë¥¼ ë°˜í™˜í•˜ëŠ” ì»¤ìŠ¤í…€ Retriever
        """
        
        print("\n" + "=" * 70)
        print("ğŸ” Hybrid Retriever ìƒì„±")
        print("=" * 70)
        print(f"  ëª¨ë“œ: {search_mode.upper()}")
        print(f"  ë°˜í™˜ íƒ€ì…: List[Document]")
        
        return HybridRetriever(
            hybrid_rag=self,
            search_mode=search_mode,
            vector_k=vector_k
        )
    
    def get_schema_info(self):
        """í•™ìŠµëœ ê·¸ë˜í”„ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¶œë ¥"""
        
        print("\n" + "=" * 70)
        print("ğŸ“Š ê·¸ë˜í”„ ìŠ¤í‚¤ë§ˆ ì •ë³´")
        print("=" * 70)
        
        if not self.discovered_node_types:
            print("  âš ï¸  ì•„ì§ ê·¸ë˜í”„ê°€ êµ¬ì¶•ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        print("\nã€ ë…¸ë“œ íƒ€ì… ã€‘")
        for node_type in sorted(self.discovered_node_types):
            props = self.node_properties[node_type]
            print(f"\n  ğŸ“Œ {node_type}")
            if props:
                print(f"     ì†ì„±: {', '.join(sorted(props))}")
        
        print("\nã€ ê´€ê³„ íƒ€ì… ã€‘")
        for source, rel, target in sorted(self.discovered_relationships):
            props = self.rel_properties[rel]
            print(f"\n  ğŸ”— ({source}) -[{rel}]-> ({target})")
            if props:
                print(f"     ì†ì„±: {', '.join(sorted(props))}")
        
        print("\n" + "=" * 70)
    
    def query_graph_directly(self, cypher_query: str):
        """
        Cypher ì¿¼ë¦¬ ì§ì ‘ ì‹¤í–‰ (ë””ë²„ê¹…ìš©)
        
        Args:
            cypher_query: Cypher ì¿¼ë¦¬ ë¬¸ìì—´
            
        Returns:
            ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            result = self.conn.execute(cypher_query)
            return result.get_as_pl()  # Polars DataFrameìœ¼ë¡œ ë°˜í™˜
        except Exception as e:
            print(f"ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return None
    
    def get_statistics(self) -> Dict:
        """
        ì‹œìŠ¤í…œ í†µê³„ ì •ë³´ ë°˜í™˜
        
        Returns:
            í†µê³„ ë”•ì…”ë„ˆë¦¬
        """
        stats = {
            "node_types": len(self.discovered_node_types),
            "relationship_types": len(self.discovered_relationships),
            "documents": len(self.original_documents),
            "mode": "in-memory" if self.db_path == ":memory:" else "disk-based",
            "db_path": self.db_path
        }
        
        return stats
    
    def print_statistics(self):
        """ì‹œìŠ¤í…œ í†µê³„ ì •ë³´ ì¶œë ¥"""
        
        stats = self.get_statistics()
        
        print("\n" + "=" * 70)
        print("ğŸ“ˆ ì‹œìŠ¤í…œ í†µê³„")
        print("=" * 70)
        print(f"  ë…¸ë“œ íƒ€ì…: {stats['node_types']}ê°œ")
        print(f"  ê´€ê³„ íƒ€ì…: {stats['relationship_types']}ê°œ")
        print(f"  ì›ë³¸ ë¬¸ì„œ: {stats['documents']}ê°œ")
        print(f"  ì €ì¥ ëª¨ë“œ: {stats['mode']}")
        print(f"  DB ê²½ë¡œ: {stats['db_path']}")
        print("=" * 70)


class HybridRetriever(BaseRetriever):
    """
    Documents ê°ì²´ë¥¼ ì§ì ‘ ë°˜í™˜í•˜ëŠ” ì»¤ìŠ¤í…€ Retriever
    LLM ë‹µë³€ ìƒì„± ì—†ì´ ê²€ìƒ‰ëœ ë¬¸ì„œë§Œ ë°˜í™˜
    """
    
    hybrid_rag: HybridKuzuRAG
    search_mode: str = "both"
    vector_k: int = 5
    
    class Config:
        arbitrary_types_allowed = True
    
    def _get_relevant_documents(
        self, 
        query: str, 
        *, 
        run_manager: Optional[CallbackManagerForRetrieverRun] = None
    ) -> List[Document]:
        """
        ê²€ìƒ‰ ì‹¤í–‰ ë° Documents ë°˜í™˜
        
        Args:
            query: ê²€ìƒ‰ ì§ˆì˜
            
        Returns:
            ê²€ìƒ‰ëœ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸
        """
        documents = []
        
        # ========================================
        # 1. ê·¸ë˜í”„ ê²€ìƒ‰
        # ========================================
        if self.search_mode in ["graph", "both"]:
            try:
                # Cypher ì¿¼ë¦¬ ìƒì„± ë° ì‹¤í–‰
                graph_result = self.hybrid_rag.graph_chain.invoke(query)
                
                # ê·¸ë˜í”„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ Documentë¡œ ë³€í™˜
                graph_content = graph_result.get('result', '')
                
                if graph_content and graph_content != '':
                    graph_doc = Document(
                        page_content=graph_content,
                        metadata={
                            "source": "graph_search",
                            "search_type": "graph",
                            "query": query
                        }
                    )
                    documents.append(graph_doc)
            
            except Exception as e:
                print(f"  âš ï¸  ê·¸ë˜í”„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        # ========================================
        # 2. ë²¡í„° ê²€ìƒ‰
        # ========================================
        if self.search_mode in ["vector", "both"]:
            try:
                # ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
                vector_docs = self.hybrid_rag.vector_store.similarity_search(
                    query, 
                    k=self.vector_k
                )
                
                # ë©”íƒ€ë°ì´í„°ì— ê²€ìƒ‰ íƒ€ì… ì¶”ê°€
                for doc in vector_docs:
                    doc.metadata["search_type"] = "vector"
                    doc.metadata["query"] = query
                
                documents.extend(vector_docs)
            
            except Exception as e:
                print(f"  âš ï¸  ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        return documents
    
    async def _aget_relevant_documents(
        self, 
        query: str, 
        *, 
        run_manager: Optional[CallbackManagerForRetrieverRun] = None
    ) -> List[Document]:
        """ë¹„ë™ê¸° ê²€ìƒ‰ (ë™ê¸° ë²„ì „ í˜¸ì¶œ)"""
        return self._get_relevant_documents(query, run_manager=run_manager)